{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "like_kaggle.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moran500/testing/blob/master/like_kaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "LL5l2DEm-30O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import catboost\n",
        "from catboost import Pool\n",
        "from catboost import CatBoostRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from xgboost import plot_importance\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "# %matplotlib inline\n",
        "# sns.set(style=\"darkgrid\")\n",
        "# pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
        "# warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OJoQ0iB__FBI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load data\n",
        "test = pd.read_csv('../input/test.csv', dtype={'ID': 'int32', 'shop_id': 'int32', \n",
        "                                                  'item_id': 'int32'})\n",
        "item_categories = pd.read_csv('../input/item_categories.csv', \n",
        "                              dtype={'item_category_name': 'str', 'item_category_id': 'int32'})\n",
        "items = pd.read_csv('../input/items.csv', dtype={'item_name': 'str', 'item_id': 'int32', \n",
        "                                                 'item_category_id': 'int32'})\n",
        "shops = pd.read_csv('../input/shops.csv', dtype={'shop_name': 'str', 'shop_id': 'int32'})\n",
        "sales = pd.read_csv('../input/sales_train.csv', parse_dates=['date'], \n",
        "                    dtype={'date': 'str', 'date_block_num': 'int32', 'shop_id': 'int32', \n",
        "                          'item_id': 'int32', 'item_price': 'float32', 'item_cnt_day': 'int32'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-DRPqJ2M_L2X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# join data set\n",
        "train = sales.join(items, on='item_id', rsuffix='_').join(shops, on='shop_id', rsuffix='_').join(item_categories, on='item_category_id', rsuffix='_').drop(['item_id_', 'shop_id_', 'item_category_id_'], axis=1)\n",
        "\n",
        "print('Train rows: ', train.shape[0])\n",
        "print('Train columns: ', train.shape[1])\n",
        "\n",
        "train.head().T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-v1EZwMV_RZh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Data leakages\n",
        "# is this elimination of the data just for those which we have in data which we need to predict?\n",
        "\n",
        "test_shop_ids = test['shop_id'].unique()\n",
        "test_item_ids = test['item_id'].unique()\n",
        "# Only shops that exist in test set.\n",
        "lk_train = train[train['shop_id'].isin(test_shop_ids)]\n",
        "# Only items that exist in test set.\n",
        "lk_train = lk_train[lk_train['item_id'].isin(test_item_ids)]\n",
        "\n",
        "print('Data set size before leaking:', train.shape[0])\n",
        "print('Data set size after leaking:', lk_train.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UbQ2uHv-_4Nj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Data cleaning\n",
        "# Only records with \"item_price\" > 0.\n",
        "train = train.query('item_price > 0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Un_chb0WAS76",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Data preprocessing\n",
        "# Select only useful features.\n",
        "train_monthly = lk_train[['date', 'date_block_num', 'shop_id', 'item_category_id', 'item_id', 'item_price', 'item_cnt_day']]\n",
        "\n",
        "# Group by month in this case \"date_block_num\" and aggregate features.\n",
        "train_monthly = train_monthly.sort_values('date').groupby(['date_block_num', 'shop_id', 'item_category_id', 'item_id'], as_index=False)\n",
        "train_monthly = train_monthly.agg({'item_price':['sum', 'mean'], 'item_cnt_day':['sum', 'mean','count']})\n",
        "\n",
        "# Rename features.\n",
        "train_monthly.columns = ['date_block_num', 'shop_id', 'item_category_id', 'item_id', 'item_price', 'mean_item_price', 'item_cnt', 'mean_item_cnt', 'transactions']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TjIF4PleAcb7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Data preprocessing\n",
        "# Build a data set with all the possible combinations of ['date_block_num','shop_id','item_id'] so we won't have missing records.\n",
        "shop_ids = train_monthly['shop_id'].unique()\n",
        "item_ids = train_monthly['item_id'].unique()\n",
        "empty_df = []\n",
        "for i in range(34):\n",
        "    for shop in shop_ids:\n",
        "        for item in item_ids:\n",
        "            empty_df.append([i, shop, item])\n",
        "    \n",
        "empty_df = pd.DataFrame(empty_df, columns=['date_block_num','shop_id','item_id'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vp-7-AcEAkDt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Data preprocessing\n",
        "# Merge the train set with the complete set (missing records will be filled with 0).\n",
        "train_monthly = pd.merge(empty_df, train_monthly, on=['date_block_num','shop_id','item_id'], how='left')\n",
        "train_monthly.fillna(0, inplace=True)\n",
        "\n",
        "train_monthly.head().T\n",
        "train_monthly.describe().T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dvytLY7ZAn_0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Data preprocessing\n",
        "# Extract time based features.\n",
        "train_monthly['year'] = train_monthly['date_block_num'].apply(lambda x: ((x//12) + 2013))\n",
        "train_monthly['month'] = train_monthly['date_block_num'].apply(lambda x: (x % 12))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aztdZYS7A_EV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# EDA (Exploratory data analysis)\n",
        "# Grouping data for EDA.\n",
        "gp_month_mean = train_monthly.groupby(['month'], as_index=False)['item_cnt'].mean()\n",
        "gp_month_sum = train_monthly.groupby(['month'], as_index=False)['item_cnt'].sum()\n",
        "gp_category_mean = train_monthly.groupby(['item_category_id'], as_index=False)['item_cnt'].mean()\n",
        "gp_category_sum = train_monthly.groupby(['item_category_id'], as_index=False)['item_cnt'].sum()\n",
        "gp_shop_mean = train_monthly.groupby(['shop_id'], as_index=False)['item_cnt'].mean()\n",
        "gp_shop_sum = train_monthly.groupby(['shop_id'], as_index=False)['item_cnt'].sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r7n_76bPBKhM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# EDA\n",
        "# How sales behaves along the year?\n",
        "f, axes = plt.subplots(2, 1, figsize=(22, 10), sharex=True)\n",
        "sns.lineplot(x=\"month\", y=\"item_cnt\", data=gp_month_mean, ax=axes[0]).set_title(\"Monthly mean\")\n",
        "sns.lineplot(x=\"month\", y=\"item_cnt\", data=gp_month_sum, ax=axes[1]).set_title(\"Monthly sum\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hUsTriWfBSmU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# EDA\n",
        "# What category sells more?\n",
        "f, axes = plt.subplots(2, 1, figsize=(22, 10), sharex=True)\n",
        "sns.barplot(x=\"item_category_id\", y=\"item_cnt\", data=gp_category_mean, ax=axes[0], palette=\"rocket\").set_title(\"Monthly mean\")\n",
        "sns.barplot(x=\"item_category_id\", y=\"item_cnt\", data=gp_category_sum, ax=axes[1], palette=\"rocket\").set_title(\"Monthly sum\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WL1vWwHeBZEc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# EDA\n",
        "# What shop sells more?\n",
        "f, axes = plt.subplots(2, 1, figsize=(22, 10), sharex=True)\n",
        "sns.barplot(x=\"shop_id\", y=\"item_cnt\", data=gp_shop_mean, ax=axes[0], palette=\"rocket\").set_title(\"Monthly mean\")\n",
        "sns.barplot(x=\"shop_id\", y=\"item_cnt\", data=gp_shop_sum, ax=axes[1], palette=\"rocket\").set_title(\"Monthly sum\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KZGfopoXBtFL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# EDA\n",
        "# Check outliers\n",
        "sns.jointplot(x=\"item_cnt\", y=\"item_price\", data=train_monthly, height=8)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NMceZ6p0BziD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# EDA\n",
        "# Check outliers\n",
        "sns.jointplot(x=\"item_cnt\", y=\"transactions\", data=train_monthly, height=8)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SAt3IvhVB6CE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# EDA\n",
        "# Feature \"item_cnt\" distribution\n",
        "plt.subplots(figsize=(22, 8))\n",
        "sns.boxplot(train_monthly['item_cnt'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aXsYJ1-ZCEdM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Removing outliers\n",
        "train_monthly = train_monthly.query('item_cnt >= 0 and item_cnt <= 20 and item_price < 400000')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pPRYl5qdCJmc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Creating the label\n",
        "train_monthly['item_cnt_month'] = train_monthly.sort_values('date_block_num').groupby(['shop_id', 'item_id'])['item_cnt'].shift(-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FSmZHDp9CVVM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Feature engineering\n",
        "# item price\n",
        "train_monthly['item_price_unit'] = train_monthly['item_price'] // train_monthly['item_cnt']\n",
        "train_monthly['item_price_unit'].fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "# group based features\n",
        "gp_item_price = train_monthly.sort_values('date_block_num').groupby(['item_id'], as_index=False).agg({'item_price':[np.min, np.max]})\n",
        "gp_item_price.columns = ['item_id', 'hist_min_item_price', 'hist_max_item_price']\n",
        "train_monthly = pd.merge(train_monthly, gp_item_price, on='item_id', how='left')\n",
        "\n",
        "\n",
        "# How much each item's price changed from its (lowest/highest) historical price\n",
        "train_monthly['price_increase'] = train_monthly['item_price'] - train_monthly['hist_min_item_price']\n",
        "train_monthly['price_decrease'] = train_monthly['hist_max_item_price'] - train_monthly['item_price']\n",
        "\n",
        "\n",
        "# Rolling window based features\n",
        "# Min value\n",
        "f_min = lambda x: x.rolling(window=3, min_periods=1).min()\n",
        "# Max value\n",
        "f_max = lambda x: x.rolling(window=3, min_periods=1).max()\n",
        "# Mean value\n",
        "f_mean = lambda x: x.rolling(window=3, min_periods=1).mean()\n",
        "# Standard deviation\n",
        "f_std = lambda x: x.rolling(window=3, min_periods=1).std()\n",
        "\n",
        "function_list = [f_min, f_max, f_mean, f_std]\n",
        "function_name = ['min', 'max', 'mean', 'std']\n",
        "\n",
        "for i in range(len(function_list)):\n",
        "    train_monthly[('item_cnt_%s' % function_name[i])] = train_monthly.sort_values('date_block_num').groupby(['shop_id', 'item_category_id', 'item_id'])['item_cnt'].apply(function_list[i])\n",
        "\n",
        "# Fill the empty std features with 0\n",
        "train_monthly['item_cnt_std'].fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "# Lag based features\n",
        "lag_list = [1, 2, 3]\n",
        "\n",
        "for lag in lag_list:\n",
        "    ft_name = ('item_cnt_shifted%s' % lag)\n",
        "    train_monthly[ft_name] = train_monthly.sort_values('date_block_num').groupby(['shop_id', 'item_category_id', 'item_id'])['item_cnt'].shift(lag)\n",
        "    # Fill the empty shifted features with 0\n",
        "    train_monthly[ft_name].fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "# Item sales count trend\n",
        "train_monthly['item_trend'] = train_monthly['item_cnt']\n",
        "\n",
        "for lag in lag_list:\n",
        "    ft_name = ('item_cnt_shifted%s' % lag)\n",
        "    train_monthly['item_trend'] -= train_monthly[ft_name]\n",
        "\n",
        "train_monthly['item_trend'] /= len(lag_list) + 1\n",
        "\n",
        "\n",
        "train_monthly.head().T\n",
        "train_monthly.describe().T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L-zo0SauDAUM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Train and validation split\n",
        "train_set = train_monthly.query('date_block_num >= 3 and date_block_num < 28').copy()\n",
        "validation_set = train_monthly.query('date_block_num >= 28 and date_block_num < 33').copy()\n",
        "test_set = train_monthly.query('date_block_num == 33').copy()\n",
        "\n",
        "train_set.dropna(subset=['item_cnt_month'], inplace=True)\n",
        "validation_set.dropna(subset=['item_cnt_month'], inplace=True)\n",
        "\n",
        "train_set.dropna(inplace=True)\n",
        "validation_set.dropna(inplace=True)\n",
        "\n",
        "print('Train set records:', train_set.shape[0])\n",
        "print('Validation set records:', validation_set.shape[0])\n",
        "print('Test set records:', test_set.shape[0])\n",
        "\n",
        "print('Train set records: %s (%.f%% of complete data)' % (train_set.shape[0], ((train_set.shape[0]/train_monthly.shape[0])*100)))\n",
        "print('Validation set records: %s (%.f%% of complete data)' % (validation_set.shape[0], ((validation_set.shape[0]/train_monthly.shape[0])*100)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xZIVOBptDWD_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# mean encoding\n",
        "# Shop mean encoding.\n",
        "gp_shop_mean = train_set.groupby(['shop_id']).agg({'item_cnt_month': ['mean']})\n",
        "gp_shop_mean.columns = ['shop_mean']\n",
        "gp_shop_mean.reset_index(inplace=True)\n",
        "# Item mean encoding.\n",
        "gp_item_mean = train_set.groupby(['item_id']).agg({'item_cnt_month': ['mean']})\n",
        "gp_item_mean.columns = ['item_mean']\n",
        "gp_item_mean.reset_index(inplace=True)\n",
        "# Shop with item mean encoding.\n",
        "gp_shop_item_mean = train_set.groupby(['shop_id', 'item_id']).agg({'item_cnt_month': ['mean']})\n",
        "gp_shop_item_mean.columns = ['shop_item_mean']\n",
        "gp_shop_item_mean.reset_index(inplace=True)\n",
        "# Year mean encoding.\n",
        "gp_year_mean = train_set.groupby(['year']).agg({'item_cnt_month': ['mean']})\n",
        "gp_year_mean.columns = ['year_mean']\n",
        "gp_year_mean.reset_index(inplace=True)\n",
        "# Month mean encoding.\n",
        "gp_month_mean = train_set.groupby(['month']).agg({'item_cnt_month': ['mean']})\n",
        "gp_month_mean.columns = ['month_mean']\n",
        "gp_month_mean.reset_index(inplace=True)\n",
        "\n",
        "# Add meand encoding features to train set.\n",
        "train_set = pd.merge(train_set, gp_shop_mean, on=['shop_id'], how='left')\n",
        "train_set = pd.merge(train_set, gp_item_mean, on=['item_id'], how='left')\n",
        "train_set = pd.merge(train_set, gp_shop_item_mean, on=['shop_id', 'item_id'], how='left')\n",
        "train_set = pd.merge(train_set, gp_year_mean, on=['year'], how='left')\n",
        "train_set = pd.merge(train_set, gp_month_mean, on=['month'], how='left')\n",
        "# Add meand encoding features to validation set.\n",
        "validation_set = pd.merge(validation_set, gp_shop_mean, on=['shop_id'], how='left')\n",
        "validation_set = pd.merge(validation_set, gp_item_mean, on=['item_id'], how='left')\n",
        "validation_set = pd.merge(validation_set, gp_shop_item_mean, on=['shop_id', 'item_id'], how='left')\n",
        "validation_set = pd.merge(validation_set, gp_year_mean, on=['year'], how='left')\n",
        "validation_set = pd.merge(validation_set, gp_month_mean, on=['month'], how='left')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QViiM89WDi2-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create train and validation sets and labels. \n",
        "X_train = train_set.drop(['item_cnt_month', 'date_block_num'], axis=1)\n",
        "Y_train = train_set['item_cnt_month'].astype(int)\n",
        "X_validation = validation_set.drop(['item_cnt_month', 'date_block_num'], axis=1)\n",
        "Y_validation = validation_set['item_cnt_month'].astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dTrSptTtDkZV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Integer features (used by catboost model).\n",
        "int_features = ['shop_id', 'item_id', 'year', 'month']\n",
        "\n",
        "X_train[int_features] = X_train[int_features].astype('int32')\n",
        "X_validation[int_features] = X_validation[int_features].astype('int32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z1XXvyp4DniU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Build test set\n",
        "latest_records = pd.concat([train_set, validation_set]).drop_duplicates(subset=['shop_id', 'item_id'], keep='last')\n",
        "X_test = pd.merge(test, latest_records, on=['shop_id', 'item_id'], how='left', suffixes=['', '_'])\n",
        "X_test['year'] = 2015\n",
        "X_test['month'] = 9\n",
        "X_test.drop('item_cnt_month', axis=1, inplace=True)\n",
        "X_test[int_features] = X_test[int_features].astype('int32')\n",
        "X_test = X_test[X_train.columns]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tlgIkngNDsNl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Replacing missing values\n",
        "sets = [X_train, X_validation, X_test]\n",
        "\n",
        "# This was taking too long.\n",
        "# Replace missing values with the median of each item.\n",
        "for dataset in sets:\n",
        "    for item_id in dataset['item_id'].unique():\n",
        "        for column in dataset.columns:\n",
        "            item_median = dataset[(dataset['item_id'] == item_id)][column].median()\n",
        "            dataset.loc[(dataset[column].isnull()) & (dataset['item_id'] == item_id), column] = item_median\n",
        "\n",
        "# Replace missing values with the median of each shop.            \n",
        "for dataset in sets:\n",
        "    for shop_id in dataset['shop_id'].unique():\n",
        "        for column in dataset.columns:\n",
        "            shop_median = dataset[(dataset['shop_id'] == shop_id)][column].median()\n",
        "            dataset.loc[(dataset[column].isnull()) & (dataset['shop_id'] == shop_id), column] = shop_median\n",
        "            \n",
        "# Fill remaining missing values on test set with mean.\n",
        "X_test.fillna(X_test.mean(), inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wvw9XyatD3AM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# I'm dropping \"item_category_id\", we don't have it on test set and would be a little hard to create categories for items that exist only on test set.\n",
        "X_train.drop(['item_category_id'], axis=1, inplace=True)\n",
        "X_validation.drop(['item_category_id'], axis=1, inplace=True)\n",
        "X_test.drop(['item_category_id'], axis=1, inplace=True)\n",
        "\n",
        "X_test.head().T\n",
        "X_test.describe().T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2wsDJbonPke3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# XGBoost\n",
        "# Use only part of features on XGBoost.\n",
        "xgb_features = ['item_cnt','item_cnt_mean', 'item_cnt_std', 'item_cnt_shifted1', \n",
        "                'item_cnt_shifted2', 'item_cnt_shifted3', 'shop_mean', \n",
        "                'shop_item_mean', 'item_trend', 'mean_item_cnt']\n",
        "xgb_train = X_train[xgb_features]\n",
        "xgb_val = X_validation[xgb_features]\n",
        "xgb_test = X_test[xgb_features]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ugHWSIEpQbTW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# XGBoost\n",
        "xgb_model = XGBRegressor(max_depth=8, \n",
        "                         n_estimators=500, \n",
        "                         min_child_weight=1000,  \n",
        "                         colsample_bytree=0.7, \n",
        "                         subsample=0.7, \n",
        "                         eta=0.3, \n",
        "                         seed=0)\n",
        "xgb_model.fit(xgb_train, \n",
        "              Y_train, \n",
        "              eval_metric=\"rmse\", \n",
        "              eval_set=[(xgb_train, Y_train), (xgb_val, Y_validation)], \n",
        "              verbose=20, \n",
        "              early_stopping_rounds=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CgEoRjJTQnG_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# XGBoost\n",
        "xgb_train_pred = xgb_model.predict(xgb_train)\n",
        "xgb_val_pred = xgb_model.predict(xgb_val)\n",
        "xgb_test_pred = xgb_model.predict(xgb_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ru9q6G5pQwGB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# XGBoost\n",
        "def model_performance_sc_plot(predictions, labels, title):\n",
        "    # Get min and max values of the predictions and labels.\n",
        "    min_val = max(max(predictions), max(labels))\n",
        "    max_val = min(min(predictions), min(labels))\n",
        "    # Create dataframe with predicitons and labels.\n",
        "    performance_df = pd.DataFrame({\"Label\":labels})\n",
        "    performance_df[\"Prediction\"] = predictions\n",
        "    # Plot data\n",
        "    sns.jointplot(y=\"Label\", x=\"Prediction\", data=performance_df, kind=\"reg\", height=7)\n",
        "    plt.plot([min_val, max_val], [min_val, max_val], 'm--')\n",
        "    plt.title(title, fontsize=9)\n",
        "    plt.show()\n",
        "    \n",
        "# model_performance_sc_plot(catboost_train_pred, Y_train, 'Train')\n",
        "model_performance_sc_plot(xgb_val_pred, Y_validation, 'Validation')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}